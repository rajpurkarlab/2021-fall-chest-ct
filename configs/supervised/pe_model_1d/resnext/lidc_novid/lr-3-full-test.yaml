experiment_name: 'lidc_1d_resnext101_novid_full'
trial_name: 'lr-3'
phase: 'test'
checkpoint: '/deep2/u/alexke/pe_models_benchmark/data/ckpt/lidc_1d_resnext101_novid_full_lr-3/1/2022_03_13_16_46_22/epoch=15-step=351.ckpt'

lightning:
  trainer:
    gpus: 1
    # distributed_backend: 'ddp' # put on if more than one gpu
    max_epochs: 50
    precision: 16
    lr: 1e-3
    auto_lr_find: false
    benchmark: true
    profiler: 'simple'
    replace_sampler_ddp: false
    # limit_train_batches: 0.1 # for sweep over 10% of data to find best learning rate
  checkpoint_callback:
    monitor: 'val/mean_auroc'
    dirpath: './data/ckpt'
    save_last: true
    mode: 'max'
    save_top_k: 10
  early_stopping_callback:
    monitor: 'val/mean_auroc'
    min_delta: 0.00
    patience: 5
    verbose: False
    mode: 'max'
  logger:
    logger_type: 'WandbLogger'
    save_dir: './data/logger/'
    name: 'lrcn_resnext101'
    project: 'pe_models'

model:
  type: 'model_1d'
  aggregation: 'mean' # mean, max, attention
  seq_encoder:
    rnn_type: 'GRU' # lstm, gru
    hidden_size: 256
    bidirectional: True
    num_layers: 1
    dropout_prob: 0.5

data:
  use_hdf5: true
  hdf5_path: '/deep2/u/alexke/pe_models_benchmark/data/output/lidc_2d_resnext101_novid_full_lr-3_positive_only_weighted_sample/1/2022_03_11_15_04_45/features.hdf5'
  feature_size: 2048
  dataset: 'rsna'
  type: 'lidc-1d'     # 1d, 2d, 3d, window
  targets: 'rsna_pe_target'
  num_slices: 150
  sample_strategy: 'random' # fix, random
  contextualize_slice: true
  weighted_sample: false 
 
train:
  batch_size: 32
  num_workers: 8
  weighted_loss: false
  loss_fn:
    name: 'BCEWithLogitsLoss'
  optimizer:
    name: 'Adam'
    weight_decay: 1e-6
  scheduler:
    name: 'ReduceLROnPlateau'
    monitor: 'val/mean_auroc'
    interval: 'epoch'
    frequency: 3
    factor: 0.5
    patience: 5